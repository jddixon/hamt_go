hamt_go/TODO

2014-04-25
    * determine why table_test fails with w > 6 but hamt_test succeeds

2014-04-24
    * modify Root.insertEntry to replace values where there is an
        exact match on key ('DUPLICATE KEYS')
    * test insertion of dupe keys
    * modify Table.insertEntry to replace values where there is an
        exact match on key
    * test insertion of dupe keys
    * consider merging Table.insertEntry and insertIntoOccupiedSlot
    * modify TestTableEntrySplittingInserts to verify that table count  * DONE
        is as expected                                                  * DONE
    * create TestHAMTEntrySplittingInserts modeled on the above         * DONE
        - verify that table count is as expected                        * DONE

2014-04-23
    * clean up code: find MERGE THIS and do it (Table.insertEntry)      * DONE
    * powerOfTwo() is a bit silly (panics if n too large); could make   * GONE
        it lazy ;-)                                                     * GONE
    * need performance test which runs as a command, always does same
        number of ops (eg 10^6)
    * need performance test which is say 1% inserts, 99% finds, 
        and so forth
    * same test but with varying degrees of concurrency

2014-04-22
    * change logic so that root table has 2^t slots, with no            * DONE
        compression (ie, we don't use popcount at the root)             * DONE
    * w cannot exceed 6 because POPCOUNT is limited to a 64-bit range
    * values in the root table should NOT be entries; the index
        is known.  Make these Nodes instead.  This may be URGENT.
    * DEBUG: tests of HAMT using Root largely succeed, except that
        reconfirmation of presence of root value fails around line
        175 in hamt_test.go 

2014-04-21 
    * FIX: insertIntoOccupiedSlot() does not replace the value 
        where there is an exact match on keys
    * need to add buckets to handle exact matches on 64 bit keys
        (however very unlikely such matches may be in actual use)
    * drop HAMT32, HAMT64, and related bits and pieces                  * DONE
    * FIX: w=7 and w=8 versions of the HAMT benchmark have stopped
        working
    * modify code to actually use t (w = 5, t = 5 yield 1K slot root)

2014-04-20 (rev branch)
    * investigate: TestTableEntrySplittingInserts creates two tables    
        for each key inserted - should create only one                  
    * investigate: Table.maxSlots never used

2014-04-19 (rev branch)
    * produce hamt.go with root table size 2^T slots, all other		    * DONE
        tables 2^W slots		                                        * DONE
    * this begins as copies of the dev branch hamt32.go, etc            * DONE

2014-04-18
    * hamt64_perf_test.go                                               * DONE
        - 10^6 run with 32-byte keys about 2700ns/op, 450 MB RAM
        - idMap about 2050 ns/op, 1 GB RAM (uses 256 slot tables)
    * Need to benchmark HAMT64 with different sizes of root table       * SKIP
    * Need buckets at max depth to do hamt32_perf_test (million-entry
        trie too deep for HAMT32)

    * Need GetLeafCount() and GetTableCount() functions for both        * DONE
        HAMT32 and HAMT64                                               * DONE
    * Possibly change meaning of 'depth' to bitDepth
    * Possibly break connection between wordlenth (32 or 64) and
        W (log base 2 of number of entries in table)

    * Need to test GetLeafCount() and GetTableCount() functions
        for both HAMT32 and HAMT64
    * Investigate suspicion that while larger root table has a small
        positive effect on performance, larger tables elsewhere cause
        a large increase in memory consumption.

2014-04-17
    * consider allowing larger root table of 2^(t + W) entries
    * then possibly allow dynamic resizing
        - this might be restricted to tables of 2^(N * W) entries
    * need tools for static analysis of frozen HAMTs
    * possibly need serialization/deserialization tools

    * start 'dev' branch, do new work there, with only urgent           * DONE
        bugfixes on the master branch.

2014-04-16
    * clean up, save, step version number                               * DONE
    * to make this thing more useful:
        - add buckets at the bottom level (in a 32K run, with random    * SKIP
            keys, there were 6 entries at level 6, 150 at level5)		* SKIP
            * moved to 64-bit keys, making this far less urgent		    * SKIP
        - where Table32.Delete() leaves empty table, need to remove
            the table from the data structure - recursively
    * documentation needs to mention POPCNT/SWAR                        * DONE

2014-04-05
    * implement HAMT32 and tests first, then HAMT64 and tests           * DONE

2014-04-04
    * need perf tests, all 6 variants (32,64 * 3)
        * must clearly identify OS, hardware, Go version
    * eventually need option to use hardware POPCNT if available
    * need docs
        - and figures
        - docs, figures get imported into gh-pages
    * project README should refer to github.io (ie, gh-pages)
